# STEP 28: Fine-tuning

ëª¨ë¸ì„ ì§ì ‘ í•™ìŠµì‹œì¼œ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

---

## Fine-tuningì´ë€?

ê¸°ì¡´ ëª¨ë¸(Pre-trained Model)ì„ íŠ¹ì • ëª©ì ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

```
GPT-4 (ë²”ìš©) + ìš°ë¦¬ ë°ì´í„° â†’ ìš°ë¦¬ ì „ìš© ëª¨ë¸
```

### ë¹„ìœ 

```
ê¸°ë³¸ ìš”ë¦¬ì‚¬ (Pre-trained)
    â†“ + í•œì‹ ë ˆì‹œí”¼ í•™ìŠµ
í•œì‹ ì „ë¬¸ ìš”ë¦¬ì‚¬ (Fine-tuned)
```

---

## ì–¸ì œ Fine-tuningì´ í•„ìš”í•œê°€?

### RAGë¡œ ì¶©ë¶„í•œ ê²½ìš°

- ìµœì‹  ì •ë³´ ì œê³µ
- íŠ¹ì • ë¬¸ì„œ ê¸°ë°˜ Q&A
- íŒ©íŠ¸ ê¸°ë°˜ ë‹µë³€

### Fine-tuningì´ í•„ìš”í•œ ê²½ìš°

- íŠ¹ì • **ìŠ¤íƒ€ì¼**ë¡œ ë‹µë³€ (ë§íˆ¬, í˜•ì‹)
- íŠ¹ì • **í–‰ë™** í•™ìŠµ (í•­ìƒ JSONìœ¼ë¡œ ì‘ë‹µ)
- **ë„ë©”ì¸ ì „ë¬¸ì„±** (ì˜ë£Œ, ë²•ë¥  ìš©ì–´)
- **ì¼ê´€ëœ ì„±ê²©** (ìºë¦­í„° AI)

### ì˜ˆì‹œ

```
# RAGë¡œ ì¶©ë¶„
"ì´ ê³„ì•½ì„œì—ì„œ ìœ„ì•½ê¸ˆ ì¡°í•­ì„ ì°¾ì•„ì¤˜"

# Fine-tuning í•„ìš”
"ëª¨ë“  ë‹µë³€ì„ ë²•ë¥  ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´"
"í•­ìƒ ì¹œê·¼í•œ ë°˜ë§ë¡œ ëŒ€í™”í•´"
```

---

## Fine-tuning ë°©ì‹

### 1. Full Fine-tuning

ëª¨ë¸ ì „ì²´ë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

```
ì¥ì : ìµœê³  ì„±ëŠ¥
ë‹¨ì : ë¹„ìš© ë§¤ìš° ë†’ìŒ, GPU ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”
```

### 2. LoRA (Low-Rank Adaptation)

ëª¨ë¸ì˜ ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

```
ì¥ì : íš¨ìœ¨ì , ì ì€ ë©”ëª¨ë¦¬
ë‹¨ì : Fullë³´ë‹¤ ì„±ëŠ¥ ì•½ê°„ ë‚®ì„ ìˆ˜ ìˆìŒ
```

### 3. QLoRA

LoRA + ì–‘ìí™”(Quantization)

```
ì¥ì : ë” ì ì€ ë©”ëª¨ë¦¬ (ì¼ë°˜ GPUì—ì„œ ê°€ëŠ¥)
ë‹¨ì : ì†ë„ ì•½ê°„ ëŠë¦¼
```

ëŒ€ë¶€ë¶„ **LoRA** ë˜ëŠ” **QLoRA**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ë°ì´í„° ì¤€ë¹„

Fine-tuningì˜ í•µì‹¬ì€ **ì¢‹ì€ ë°ì´í„°**ì…ë‹ˆë‹¤.

### ë°ì´í„° í˜•ì‹

```json
{"messages": [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ìƒë‹´ì›ì…ë‹ˆë‹¤."},
    {"role": "user", "content": "ë°°ì†¡ì´ ì–¸ì œ ì˜¤ë‚˜ìš”?"},
    {"role": "assistant", "content": "ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ í™•ì¸í•´ë“œë¦´ê²Œìš”! ğŸ˜Š"}
]}

{"messages": [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ìƒë‹´ì›ì…ë‹ˆë‹¤."},
    {"role": "user", "content": "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"},
    {"role": "assistant", "content": "ë„¤, í™˜ë¶ˆ ë„ì™€ë“œë¦´ê²Œìš”. ì£¼ë¬¸ë²ˆí˜¸ì™€ ì‚¬ìœ ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”!"}
]}
```

### ë°ì´í„° ì–‘ ê°€ì´ë“œ

| ëª©ì  | ìµœì†Œ ë°ì´í„° | ê¶Œì¥ ë°ì´í„° |
|------|-------------|-------------|
| ìŠ¤íƒ€ì¼ ë³€ê²½ | 50ê°œ | 200-500ê°œ |
| ìƒˆë¡œìš´ ì‘ì—… | 100ê°œ | 500-1000ê°œ |
| ë„ë©”ì¸ ì „ë¬¸ì„± | 500ê°œ | 2000ê°œ+ |

### ë°ì´í„° í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
âœ… ì¼ê´€ëœ í˜•ì‹
âœ… ì •í™•í•œ ì •ë³´
âœ… ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤
âœ… ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ ë°˜ì˜
âŒ ì¤‘ë³µ ì œê±°
âŒ ì˜¤íƒ€/ì—ëŸ¬ ìˆ˜ì •
```

---

## OpenAI Fine-tuning

### 1. ë°ì´í„° ì—…ë¡œë“œ

```python
from openai import OpenAI
client = OpenAI()

# íŒŒì¼ ì—…ë¡œë“œ
file = client.files.create(
    file=open("training_data.jsonl", "rb"),
    purpose="fine-tune"
)
```

### 2. Fine-tuning ì‘ì—… ìƒì„±

```python
job = client.fine_tuning.jobs.create(
    training_file=file.id,
    model="gpt-4o-mini-2024-07-18",
    hyperparameters={
        "n_epochs": 3,
        "learning_rate_multiplier": 0.1
    }
)
```

### 3. ìƒíƒœ í™•ì¸

```python
# ì§„í–‰ ìƒí™© í™•ì¸
job = client.fine_tuning.jobs.retrieve(job.id)
print(job.status)  # "running", "succeeded", "failed"

# ì´ë²¤íŠ¸ í™•ì¸
events = client.fine_tuning.jobs.list_events(job.id)
for event in events:
    print(event.message)
```

### 4. ì‚¬ìš©

```python
response = client.chat.completions.create(
    model="ft:gpt-4o-mini:my-org::abc123",  # Fine-tuned ëª¨ë¸ ID
    messages=[
        {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}
    ]
)
```

---

## LoRAë¡œ ì§ì ‘ í•™ìŠµ (Ollama)

ë¡œì»¬ì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì„ Fine-tuningí•©ë‹ˆë‹¤.

### 1. í™˜ê²½ ì„¤ì •

```bash
# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install transformers peft datasets accelerate bitsandbytes
```

### 2. ëª¨ë¸ ë¡œë“œ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model

# ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
model_name = "meta-llama/Llama-2-7b-hf"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,  # QLoRA
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### 3. LoRA ì„¤ì •

```python
lora_config = LoraConfig(
    r=16,               # LoRA rank
    lora_alpha=32,      # ìŠ¤ì¼€ì¼ë§
    target_modules=["q_proj", "v_proj"],  # ì ìš© ë ˆì´ì–´
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
# trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06%
```

### 4. í•™ìŠµ

```python
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    learning_rate=2e-4,
    logging_steps=10,
    save_steps=100
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset
)

trainer.train()
```

### 5. ì €ì¥ ë° ì‚¬ìš©

```python
# LoRA ì–´ëŒ‘í„° ì €ì¥
model.save_pretrained("./my-lora-adapter")

# ë‚˜ì¤‘ì— ë¡œë“œ
from peft import PeftModel
base_model = AutoModelForCausalLM.from_pretrained(model_name)
model = PeftModel.from_pretrained(base_model, "./my-lora-adapter")
```

---

## Fine-tuning íŒ

### 1. ì‘ê²Œ ì‹œì‘

```
ì²˜ìŒ: 50ê°œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
í™•ì¸: ì›í•˜ëŠ” ë°©í–¥ì¸ì§€ ê²€ì¦
í™•ì¥: ë°ì´í„° ì¶”ê°€í•˜ë©° ê°œì„ 
```

### 2. í‰ê°€ ì„¸íŠ¸ ë¶„ë¦¬

```python
# 80% í•™ìŠµ, 20% í‰ê°€
train_data, eval_data = dataset.train_test_split(test_size=0.2)
```

### 3. ê³¼ì í•© ì£¼ì˜

```
ì¦ìƒ: í•™ìŠµ ë°ì´í„°ëŠ” ì˜ ë§ì§€ë§Œ ìƒˆ ì…ë ¥ì— ì´ìƒí•œ ë‹µë³€
í•´ê²°: ì—í­ ì¤„ì´ê¸°, ë°ì´í„° ë‹¤ì–‘í™”
```

### 4. ë² ì´ìŠ¤ ëª¨ë¸ ì„ íƒ

```
ë¹ ë¥¸ ì‘ë‹µ í•„ìš” â†’ ì‘ì€ ëª¨ë¸ (7B)
ë†’ì€ í’ˆì§ˆ í•„ìš” â†’ í° ëª¨ë¸ (70B)
ë‹¤êµ­ì–´ â†’ ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸
```

---

## ë¹„ìš© ë¹„êµ

| ë°©ì‹ | ì´ˆê¸° ë¹„ìš© | ìš´ì˜ ë¹„ìš© | ì í•©í•œ ê²½ìš° |
|------|-----------|-----------|-------------|
| í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ | ì—†ìŒ | í† í°ë‹¹ ê³¼ê¸ˆ | ë¹ ë¥¸ ì‹¤í—˜ |
| RAG | Vector DB | í† í°ë‹¹ ê³¼ê¸ˆ | ë¬¸ì„œ ê¸°ë°˜ |
| OpenAI Fine-tuning | $15-100 | í† í°ë‹¹ ê³¼ê¸ˆ (ì €ë ´) | ìŠ¤íƒ€ì¼ ë³€ê²½ |
| ìì²´ Fine-tuning | GPU ë¹„ìš© | í˜¸ìŠ¤íŒ… ë¹„ìš© | ì™„ì „ ì»¤ìŠ¤í…€ |

---

## í•µì‹¬ ì •ë¦¬

```
Fine-tuning = ê¸°ì¡´ ëª¨ë¸ + ì¶”ê°€ í•™ìŠµ

ì–¸ì œ í•„ìš”?
- íŠ¹ì • ìŠ¤íƒ€ì¼/í˜•ì‹
- ë„ë©”ì¸ ì „ë¬¸ì„±
- ì¼ê´€ëœ í–‰ë™

ì–´ë–»ê²Œ?
- OpenAI: ì‰¬ì›€, ë¹„ìš© ë°œìƒ
- LoRA: íš¨ìœ¨ì , GPU í•„ìš”
- QLoRA: ë©”ëª¨ë¦¬ ì ˆì•½
```

**í•µì‹¬ í¬ì¸íŠ¸:**
- ì¢‹ì€ ë°ì´í„°ê°€ ê°€ì¥ ì¤‘ìš”
- ì‘ê²Œ ì‹œì‘í•´ì„œ ì ì§„ì  ê°œì„ 
- í”„ë¡¬í”„íŠ¸/RAGë¡œ ì•ˆ ë˜ë©´ Fine-tuning

---

## ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ STEPì—ì„œëŠ” ë©€í‹°ëª¨ë‹¬ì„ ë‹¤ë£¹ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¿ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ìŒì„±ë„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
